# Learning Human Pose Estimation Features with Convolutional Networks

### ICLR 2014

## Abstract

作者介绍了一种使用多层卷积网络结构的人体姿势估计模型，以及可学习低层特征和高层弱空间模型的改进的学习方法。

文章主要贡献：

* 首次展示深度学习模型能很好地完成无约束的姿态估计任务。
* 发现在仅覆盖图像上几个像素的区域上就可以学习强大的低级特征检测器
* 作者以 bottom-up 模型和弱空间模型超过了当时最佳模型

## 1 Introduction

高自由度的人体人体姿态是 CV 领域最复杂的任务之一，尤其是不使用启发式模型对单个图像进行事先假设，而直接在复杂背景中定位人体关键部位占据的很小的几个像素点。

* 之前表现最好的姿态估计方法（DPM）通常基于**身体部位检测器**：包含多个步骤
  1. 提取图像的低级特征：SIFT、HoG etc 获取局部 patch 的统计信息
  2. 将低级特征整合到局部空间域
  3. 将聚合特征映射成向量，传入具体任务中
* 深度学习方法：该方法在一般的物体识别任务中得到认可，但在姿态估计中面临挑战，包括：身体的非刚性结构、精度不足、姿势的复杂多峰的性质。

作者基于卷积网络提出的人体姿态估计的 end-to-end 模型，使得卷积网络能在姿态估计领域起作用。作者提出了一种两阶段的特征检测 pipeline

## 2 Related Work

*  sliding-window 局部检测器
* "bag of features" + regression /  SVM /  nearest neighbo
* 局部检测 + 结构推理
* 图形结构（姿态、parts-based 模型）

## 3 Model

用卷积网络做姿势估计，最明显的方法是将图像输入直接映射到关节姿势的编码向量。 卷积输出关节的位置，或者表示关节角度的层次结构。 但作者发现该方法效果很差。 一个问题是，池化虽然利于物体识别过程中的平移不变性，但会破坏精确预测姿势所必需的精确空间信息。另一个问题是，从输入空间到运动人体姿态编码的直接映射是高度非线性的。即使选择这种直接映射，大多数情况下，网络会将输入映射到无效姿势的空间。

作者发现训练多个卷积网络以执行独立的身体部位二分类，每个特征使用一个网络能实现更好的效果。这些卷积作为滑动窗口应用于输入的区域，并将像素窗口映射到单个二进制输出：存在或不存在该身体部位。该网络的最终输出结果是得到一个响应图，表示某个身体部位在该位置的置信度。再由检测出的关键部位位置推理出人体姿势。

### 3.1 Convolutional Network Architecture

作者的两阶段的特征检测 pipeline 模型基于标准的卷积神经网络结构，如下图：

![image-20200823190221136](https://i.loli.net/2020/08/23/QdyYC6eUV34EOjZ.png)

图片首先进行了局部对比归一化（LCN）以强调。。

**卷积模型结构**：

* 局部对比归一化（LCN）：增强几何的不连续性并提高泛化性能
* 三个卷积和二次采样层处理，这三个层使用 ReLU 激活和 MaxPool 
  * MaxPool 仅使用 2×2 池化的两个阶段（其中总图像下采样率为4×4）
* 将最后的池化图展平为一个向量，并由三个全连接的层进行处理

**卷积网络训练**：

作者使用批量随机梯度下降。 并预留了一个验证集来调整网络的超参数，例如特征的数量和大小，学习率，动量系数等。作者使用 Nesterov 动量和 RMSPROP 来加速学习。并且作者在每个全连接层的输入上使用了 L2 正则化和 dropout ，以减弱过拟合

### 3.2 Enforcing Global Pose Consistency with a Spatial Model

当模型应用于验证集时，3.1节中介绍的网络的原始输出会产生许多 False-Positives 。作者认为这是由于两个因素造成的：

1. 作为卷积网络输入的小图像上下文（64×64像素或大约输入图像区域的5％）不能提供足够的模型上下文信息来执行解剖学上一致的关节位置推断
2. 训练集的大小是有限的。 因此，作者使用具有简单人体姿势的空间模型从 convnet 输出中删除强异常值。 不希望这个模型会提高接近 Ground Truth（例如10像素以内）的姿势的性能，但是它用作后期处理步骤，以消除由于异常离群值而导致的解剖学上不可能的姿势（简而言之： 根据已有的简单人体姿势把模型输出的异常姿势删掉）

下面就是介绍**如何通过构建先验的人体姿态空间模型过滤预测异常，得到联合分布**：

简单空间模型中人体关键节点连通性如下图所示：

![image-20200823203041901](https://i.loli.net/2020/08/23/YoIOBisnKHwSGmt.png)

该图抽象地展示人体的单侧关节，作者以脸部，左肩，左肘部，左手腕为例。以图像上的像素位置 $x$ 为随机变量，可得：

* 卷积网络模型生成脸部，肩膀，肘部和腕关节关于 $x$ 的响应图：$p_{fac}(x)，p_{sho}(x)，p_{elb}(x)，p_{wri}(x)$

* 空间模型生成过滤后的响应图：$\hat{p}_{fac}(x)，\hat{p}_{sho}(x)，\hat{p}_{elb}(x)，\hat{p}_{wri}(x)$ ***（该步骤目标输出）***

* 两个关节可以组成一对（pairwise）$(a,b)$ ，每个关节 pair 以 b 的位置为图像中心，在训练集上计算身体部位的先验条件概率 $p_{a|b=\vec{0}}(x)$ 得到先验条件分布图， 然后对直方图进行平滑处理（使用 Gaussian 滤波器）并进行归一化。学习到先验条件分布响应图： $p_{sho|fac=\vec 0}(x)，p_{elb|sho=\vec 0}(x)，p_{wri|elb=\vec 0}(x)$ 如下所示：

![image-20200823214534692](https://i.loli.net/2020/08/23/gyl41HGITcrapxZ.png)

> 由于对称性，先验 $p_{sho|fac=\vec 0}(x)$ 是 $p_{fac|sho=\vec 0}(x)$ 的180° 旋转（同其他相邻对）。作者没有像许多 parts-based 检测器中的标准做法那样假设简单的高斯分布来建模相邻节点的 pairwise 关系，而是发现这些非参数空间先验，以提高检测性能。

给定完整的先验条件分布和卷积一元分布后，现在可以使用类似于Sum-Product 置信度传播算法来构造每个部分的过滤分布。对于身体的部位 $i$ ，有一组相邻节点 $U$ ，则最终分布定义为：
$$
\hat p_{i} \propto p_i^\lambda \ \prod_{u \in U} (p_{i|u} * p_u)
$$
其中 $\lambda$ 是一个混合参数，并且控制每个关节的一元分布对其最终过滤分布的置信度（作者在实验中使用 $\lambda = 1$）。对数空间中，上述用于肩关节的概率变为
$$
log(\hat p_{sho}) \propto \lambda \; log(p_{sho})+log(p_{sho|fac=\vec 0} * p_{fac}) + log(p_{sho|elb=\vec0} * p_{elb})
$$

作者还对肘关节和腕关节进行等效计算。面部关节被视为特例。根据经验，作者发现用空间模型过滤对脸部分布会导致性能下降。这可能是由于convnet在定位面部位置方面做得非常好，因此从肩部检测器中获取嘈杂的证据实际上会增加不确定性。取而代之的是，对于脸部，作者使用全局先验分布 $h_{fac}$，这是通过学习训练集图像中人脸位置的位置直方图获得的，如下图所示。对数空间中，人脸的输出分布如下：
$$
log(\hat p_{fac}) \propto \lambda \; log(p_{fac}) + log(h_{fac})
$$
![image-20200823222702762](https://i.loli.net/2020/08/23/G9ms8Hh7wEzXfYd.png)

最后，由于学习到的神经网络的卷积特征和空间先验并没有明确地按比例缩放，因此必须在测试时在多个比例的图像上运行卷积和空间模型，然后使用这些比例上最可能的联合位置作为最终比例联合位置。

对于包含多人示例的数据集（已知先验），需要使用非最大抑制算法在每个比例的过滤后的响应图中找到多个局部最大值，然后从场景中每个人的最可能联合候选者中选取 top $n$。

## 4 Results

作者在 FLIC 数据集上评估了该模型

> FLIC 数据集由从各种好莱坞电影中拍摄的5003张静态RGB图像组成。数据集中的每个帧都包含至少一个正面姿势的人（面对镜头），并且每个帧均由AmazonMechanical Turk处理以获取单个人上半身关节位置的 Ground Truth 标签。 FLIC数据集对于最新的姿势估计方法极具挑战性，因为姿势不受约束，身体部位经常被遮挡，衣服和背景不一致。

作者取用数据集中的3987个图像进行训练，同时将它们水平镜像以获得一个总共3987×2 = 7974个示例。由于训练图像的比例不同，因此作者还手动注释了这些训练集图像中头部的边界框，并将其调整为标准比例。此外，作者将它们裁剪为320×240，以使肩部注释的中心位于（160px，80 px）。作者不会在测试时执行此图像标准化。按照Felzenszwalb等人的方法。在测试时，仅在一个人的图像上运行模型（1016个测试用例中的351个图像）。如第3节所述，该模型在6个不同的输入图像比例尺上运行，然后选用在这些比例尺上具有最高置信度的联合位置作为最终位置

为了训练卷积网络，作者使用 Theano ，训练时，GPU上缓存100个 batch；该系统具有两个执行的主要线程：

1. 在GPU上运行的训练函数，用于评估批处理的SGD更新； 

2. 数据分派函数，用于预处理CPU上的数据，并在以下情况下在GPU上传输数据：

   > 线程（1）完成了100个 batch 的处理。在NVIDIA TITAN GPU上训练每个卷积网络每个图块所需的时间为1.9ms（fprop + bprop）=总共41分钟。在具有5000个节点的cpu集群上进行测试。测试耗时：每张图像0.49秒（0.94倍比例尺）=总共2.8分钟NMS和空间模型花费的时间可以忽略不计。

在测试时，由于每张图像中所有窗口的权重相同，我们将学习的卷积核与完整图像进行卷积而不是单个窗口。这大大减少了在整个测试集上执行前向传播的时间。

### 4.1 Evaluation

作者使用Sapp等人提出的准确性度量：对于给定的关节精度半径，计算在半径阈值（其中距离定义为二维欧式距离，以像素为单位）内正确的测试集中的关节百分比。 作者评估了在腕部，肘部和肩部关节上的性能指标。还将本文模型与 DPM 和 MODEC 架构进行了比较，在测试所有检测器时，都使用351个图像的相同子集

![image-20200823232759390](https://i.loli.net/2020/08/23/Av9HypXozWtl27B.png)

上图表明作者的架构在三个身体部位上的性能均优于或等于MODEC和DPM检测器。对于手腕和肘关节，简单空间模型可改善约5％的测试用例（在5像素阈值下）的关节定位，这使本文模型性能优于所有其他检测器。但是，对于肩关节，空间模型实际上会降低大阈值时的关节定位精度。这可能是由于弯头上的convnet性能不佳。

不出所料，空间模型无法提高已经接近正确值的点的关节精度，但是在消除腕部和肘关节的异常值方面仍然取得了成功。上图是一个示例，其中在应用空间模型之前，较大的 False-Positive 导致不正确的关节位置，随后在应用空间模型后将其删除。

## 5 Conclusion

作者改进了无约束的人体姿势估计。卷积网络是良好的低级特征检测器，与全局先验分布结合使用时，它们的性能可以胜过更复杂和流行的模型。